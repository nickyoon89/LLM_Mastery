[34m[1mwandb[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
[34m[1mwandb[0m: You can find your API key in your browser here: https://wandb.ai/authorize
[34m[1mwandb[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:
Aborted!
terms.
For example, there are objects in two groups (as shown on the right). The objects are various shapes, where one group has 3 of them while the other has 2. When the two groups combine into one, the overall amount (sum) of the shapes become 5.

Vertical Addition

The animation above demonstrate
[34m[1mwandb[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)
[34m[1mwandb[0m: You can find your API key in your browser here: https://wandb.ai/authorize
[34m[1mwandb[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:
Aborted!
terms.
For example, there are objects in two groups (as shown on the right). The objects are various shapes, where one group has 3 of them while the other has 2. When the two groups combine into one, the overall amount (sum) of the shapes become 5.

Vertical Addition

The animation above demonstrate
Tokenizer vocab_size: 4096
[612, 370, 698, 265, 261, 684]
Once upon a time
Total data: 59.21 Million | Training: 53.29 Million | Validation: 5.92 Million
torch.Size([8, 512]) torch.Size([8, 512])
tensor([ 861,  998,  461, 4040, 2074,  373,  536,  300,  708,  604],
       device='mps:0')
tensor([ 998,  461, 4040, 2074,  373,  536,  300,  708,  604, 4051],
       device='mps:0')
